{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b98b7a9a-31a9-423b-862a-f0148800f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def simple_data_generator(root_folder, pairs, batch_size=32):\n",
    "    while True:\n",
    "        # Разбиваем список пар на подсписки размером batch_size\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            batch_masks = []\n",
    "            for image_path, mask_path in batch_pairs:\n",
    "                image = cv2.imread(image_path)\n",
    "                image = np.expand_dims(image, axis=0)  # Добавляем измерение пакета\n",
    "                batch_images.append(image)\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                mask = (mask > 0).astype(np.float32)  # Преобразуем в бинарное значение\n",
    "                mask = np.expand_dims(mask, axis=0)  # Добавляем измерение пакета\n",
    "                batch_masks.append(mask)\n",
    "            yield np.vstack(batch_images), np.vstack(batch_masks)\n",
    "\n",
    "# Корневая папка с данными\n",
    "root_folder = \"C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dae3c93-d999-4e0f-bdd0-97363825d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.binary_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa828cf2-d574-406a-8dd2-0f3f384c0a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "098bcb7e-b517-4847-8d32-09a14e739ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7f6e3-ecf0-49c8-92c9-ef92210ae016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5de11378-9b22-4da2-b270-c989aa85180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def unet(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = layers.concatenate([layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv2), conv1], axis=3)\n",
    "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same')(up1)\n",
    "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv3)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12858f54-4886-40b3-8a84-ef293029363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pairs: ('C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_light\\\\images\\\\35.png', 'C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_light\\\\masks\\\\35.png')\n",
      "Validation Pairs: 40\n"
     ]
    }
   ],
   "source": [
    "def read_image_and_mask(image_path):\n",
    "    mask_path = image_path.replace(\"images\", \"masks\")  # Получаем путь к соответствующей маске\n",
    "    return image_path, mask_path\n",
    "\n",
    "# Список пар изображений и масок\n",
    "all_image_mask_pairs = []\n",
    "\n",
    "# Обход всех папок с данными\n",
    "for folder in os.listdir(root_folder):\n",
    "    images_folder = os.path.join(root_folder, folder, \"images\")\n",
    "    image_files = glob.glob(os.path.join(images_folder, \"*.png\"))\n",
    "    # Для каждого изображения находим соответствующую маску и добавляем пару в список\n",
    "    for image_path in image_files:\n",
    "        image, mask = read_image_and_mask(image_path)\n",
    "        all_image_mask_pairs.append((image, mask))\n",
    "\n",
    "# Разделение пар на обучающую и валидационную выборки\n",
    "train_pairs, val_pairs = train_test_split(all_image_mask_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Теперь у вас есть списки пар (изображение, маска) для обучения и валидации\n",
    "print(\"Train Pairs:\", train_pairs[0])\n",
    "print(\"Validation Pairs:\", len(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "131fd2ef-10a7-4d78-9068-f79a2b113d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 35s 426ms/step - loss: 0.0161 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 33s 419ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 33s 416ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 33s 416ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 33s 416ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 34s 421ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 33s 416ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 33s 418ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 34s 422ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 34s 421ms/step - loss: 0.0156 - accuracy: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0174 - val_val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214adfd8d90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (480, 640, 3)\n",
    "\n",
    "train_generator = simple_data_generator(root_folder, train_pairs, batch_size)\n",
    "val_generator = simple_data_generator(root_folder, val_pairs, batch_size)\n",
    "\n",
    "\n",
    "# Создаем модель U-Net\n",
    "model = unet(input_shape)\n",
    "tf.keras.utils.get_custom_objects()['val_accuracy'] = val_accuracy\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'val_accuracy'])\n",
    "\n",
    "# Обучаем модель\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_pairs) // batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=len(val_pairs) // batch_size,\n",
    "          verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71ca6f59-3926-4146-b988-bbe71d0ef6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\SergeySaber\\\\Desktop\\\\AI works\\\\university\\\\labs\\\\2. vid capture\\\\resources\\\\model\\\\model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "505ed7c6-5f7b-4f47-b9a0-e588f7f48f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\0.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\1.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\10.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\11.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\12.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\13.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\14.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\15.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\16.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\17.png\n",
      "Batch 1\n",
      "Images shape: (10, 480, 640, 3)\n",
      "Masks shape: (10, 480, 640)\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\18.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\19.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\2.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\20.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\21.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\22.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\23.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\24.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\25.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\26.png\n",
      "Batch 2\n",
      "Images shape: (10, 480, 640, 3)\n",
      "Masks shape: (10, 480, 640)\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\27.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\28.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\29.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\3.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\30.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\31.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\32.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\33.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\34.png\n",
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\35.png\n",
      "Batch 3\n",
      "Images shape: (10, 480, 640, 3)\n",
      "Masks shape: (10, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "root_folder = \"C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/\"\n",
    "batch_size = 10\n",
    "gen = simple_data_generator(root_folder, batch_size=batch_size)\n",
    "\n",
    "# Генерация нескольких батчей данных и вывод их на печать\n",
    "for i in range(3):\n",
    "    batch_images, batch_masks = next(gen)\n",
    "    print(\"Batch\", i+1)\n",
    "    print(\"Images shape:\", batch_images.shape)\n",
    "    print(\"Masks shape:\", batch_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "963ca246-d2e7-42f3-9f2a-6d742e630755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\11.png\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_masks = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc00dd39-5ff2-4208-bca0-94d408ee58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\12.png\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_masks = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8afc6c0a-7351-41a5-a5e1-3c7c00f34653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\13.png\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_masks = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe3e7be-bffc-4b8e-84e6-f89515e68887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\14.png\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_masks = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59643ff6-4aa1-4086-a176-8c34a7faf8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/SergeySaber/Desktop/AI works/university/labs/2. vid capture/resources/fingertip dataset init/close_dark\\images\\15.png\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_masks = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42813b4d-feab-49bb-9b4d-9d8b7a6ae871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
